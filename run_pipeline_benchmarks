#!/usr/bin/env bash

# Gives us $MASTERS env var
source ~/spark-ec2/ec2-variables.sh
command=~/graphx/bin/run-example
# class="org.apache.spark.examples.graphx.PrePostProcessWikipedia"
class="org.apache.spark.graphx.WikiPipelineBenchmark"
epart=128
algo=pagerank
# data="wiki_top4mil"
data="enwiki-latest"
# DATE=`date +%Y-%m-%d`
DATE=`date "+%Y%m%d.%H.%M.%S"`
echo $DATE

# source ~/spark-ec2/ec2-variables.sh
# export HDFS=hdfs://$MASTERS:9000
export GRAPHLAB=/mnt/graphlab

gx_output_file=~/benchmark_output/graphx-$DATE
echo $gx_output_file

tc=/usr/bin/time
numtrials=5
numiters=10
export HDFS=hdfs://$MASTERS:9000

# Graphx Benchmark
# echo $command $class spark://$MASTERS:7077 graphx hdfs://$MASTERS:9000/$data $numiters >> $gx_output_file
# { $tc -f "TOTAL: %e seconds" $command $class spark://$MASTERS:7077 graphx $HDFS/$data $numiters; } &>> $gx_output_file


glab_output_file=~/benchmark_output/graph_lab-$DATE
echo $glab_output_file

outbase=wiki_graph_processing

#extract graph
{ $tc -f "Extract Graph: %e seconds" $command $class spark://$MASTERS:7077 extract $HDFS/$data $HDFS/$outbase; } &>> $glab_output_file

for i in $(seq 1 $numiters)
do
  start=`date "+%s"`
  # PageRank
  { $tc -f "Pagerank iter $i %e seconds" mpiexec --hostfile ~/spark-ec2/slaves -n 16 env CLASSPATH=$(hadoop classpath) \
    $GRAPHLAB/release/toolkits/graph_analytics/pagerank --graph=$HDFS/"$outbase"_edges_$i \
    --format=snap --ncpus=8 --tol=0 --iterations=20 --saveprefix=$HDFS/"$outbase"_prs; } &>> $glab_output_file

  # Connected Components
  { $tc -f "Connected Components iter $i %e seconds" mpiexec --hostfile /root/spark-ec2/slaves -n $NODES env \
    CLASSPATH=$(hadoop classpath) $GRAPHLAB/release/toolkits/graph_analytics/connected_component \
    --graph=$HDFS/"$outbase"_edges_$i --format=snap --ncpus=8; } &>> $glab_output_file


#   $TIME -f "TOTAL: %e seconds" $GL_PR_COMMAND 2>&1 | tee -a $GL_PR_FILE
  #Post processing
  { $tc -f "Analyze Graph iter $i : %e seconds" $command $class spark://$MASTERS:7077 analyze $HDFS/$outbase $i; } &>> $glab_output_file

  end=`date "+%s"`
  dur=$(( end - start ))
  echo TOTAL_TIMEX iteration "$i": $dur >> $glab_output_file
done





# 5 iterations pagerank
# iter=20
# counter=0
# partstrat="RandomVertexCut"
# while [ $counter -lt $numtrials ]; do
#   # echo "NEW RUN!!!!!" >> $file
#   # ~/rebuild-graphx -no
#   echo $command $class spark://$MASTERS:7077 $algo hdfs://$MASTERS:9000/$data --numIter=$iter --numEPart=$epart --partStrategy=$partstrat >> $file
#   #{ time %e $command $class spark://$MASTERS:7077 $algo hdfs://$MASTERS:9000/$data --numIter=$iter --numEPart=$epart ; } 2> $file
#   { $tc -f "TOTAL: %e seconds" $command $class spark://$MASTERS:7077 $algo hdfs://$MASTERS:9000/$data --numIter=$iter --numEPart=$epart --partStrategy=$partstrat; } 2>> $file
#   echo "" >> $file
#   counter=$(( $counter + 1 ))
# done


# 10 iterations pagerank
# iter=10
# counter=0
# while [ $counter -lt $numtrials ]; do
#   # echo "NEW RUN!!!!!" >> $file
#   echo $command $class spark://$MASTERS:7077 $algo hdfs://$MASTERS:9000/$data --numIter=$iter --numEPart=$epart >> $file
#   #{ time %e $command $class spark://$MASTERS:7077 $algo hdfs://$MASTERS:9000/$data --numIter=$iter --numEPart=$epart ; } 2> $file
#   { $tc -f "TOTAL: %e seconds" $command $class spark://$MASTERS:7077 $algo hdfs://$MASTERS:9000/$data --numIter=$iter --numEPart=$epart; } 2>> $file
#   echo "" >> $file
#   counter=$(( $counter + 1 ))
# done


# 20 iterations pagerank
# iter=20 counter=0
# partstrat="RandomVertexCut"
# while [ $counter -lt $numtrials ]; do
#   # echo "NEW RUN!!!!!" >> $file
#   echo $command $class spark://$MASTERS:7077 $algo hdfs://$MASTERS:9000/$data --numIter=$iter --numEPart=$epart --partStrategy=$partstrat >> $file
#   #{ time %e $command $class spark://$MASTERS:7077 $algo hdfs://$MASTERS:9000/$data --numIter=$iter --numEPart=$epart ; } 2> $file
#   { $tc -f "TOTAL: %e seconds" $command $class spark://$MASTERS:7077 $algo hdfs://$MASTERS:9000/$data --numIter=$iter --numEPart=$epart --partStrategy=$partstrat; } 2>> $file
#   echo "" >> $file
#   counter=$(( $counter + 1 ))
#   # restart the cluster because my fucking slaves keep dying
#   ~/rebuild-graphx -no
# done
# 
# iter=20
# counter=0
# partstrat="EdgePartition1D"
# while [ $counter -lt $numtrials ]; do
#   # echo "NEW RUN!!!!!" >> $file
#   echo $command $class spark://$MASTERS:7077 $algo hdfs://$MASTERS:9000/$data --numIter=$iter --numEPart=$epart --partStrategy=$partstrat >> $file
#   #{ time %e $command $class spark://$MASTERS:7077 $algo hdfs://$MASTERS:9000/$data --numIter=$iter --numEPart=$epart ; } 2> $file
#   { $tc -f "TOTAL: %e seconds" $command $class spark://$MASTERS:7077 $algo hdfs://$MASTERS:9000/$data --numIter=$iter --numEPart=$epart --partStrategy=$partstrat; } 2>> $file
#   echo "" >> $file
#   counter=$(( $counter + 1 ))
#   # restart the cluster because my fucking slaves keep dying
#   ~/rebuild-graphx -no
# done
# 
# iter=20
# counter=0
# partstrat="EdgePartition2D"
# while [ $counter -lt $numtrials ]; do
#   # echo "NEW RUN!!!!!" >> $file
#   echo $command $class spark://$MASTERS:7077 $algo hdfs://$MASTERS:9000/$data --numIter=$iter --numEPart=$epart --partStrategy=$partstrat >> $file
#   #{ time %e $command $class spark://$MASTERS:7077 $algo hdfs://$MASTERS:9000/$data --numIter=$iter --numEPart=$epart ; } 2> $file
#   { $tc -f "TOTAL: %e seconds" $command $class spark://$MASTERS:7077 $algo hdfs://$MASTERS:9000/$data --numIter=$iter --numEPart=$epart --partStrategy=$partstrat; } 2>> $file
#   echo "" >> $file
#   counter=$(( $counter + 1 ))
#   # restart the cluster because my fucking slaves keep dying
#   ~/rebuild-graphx -no
# done



# # 40 iterations pagerank
# iter=40
# counter=0
# while [ $counter -lt $numtrials ]; do
#   # echo "NEW RUN!!!!!" >> $file
#   echo $command $class spark://$MASTERS:7077 $algo hdfs://$MASTERS:9000/$data --numIter=$iter --numEPart=$epart >> $file
#   #{ time %e $command $class spark://$MASTERS:7077 $algo hdfs://$MASTERS:9000/$data --numIter=$iter --numEPart=$epart ; } 2> $file
#   { $tc -f "TOTAL: %e seconds" $command $class spark://$MASTERS:7077 $algo hdfs://$MASTERS:9000/$data --numIter=$iter --numEPart=$epart; } 2>> $file
#   echo "" >> $file
#   counter=$(( $counter + 1 ))
# done






#time ./run-example org.apache.spark.graph.Analytics spark://$MASTER:7077 pagerank hdfs://$MASTER:9000/soc-LiveJournal1.txt --numIter=2 --numEPart=128


